{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/joehawkens/MachineLearning/blob/main/MODULE_5.ipynb",
      "authorship_tag": "ABX9TyNdiRjN73D9896kHrDequRQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joehawkens/MachineLearning/blob/main/MODULE_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODULE 5\n",
        "\n",
        "- Overview: https://byui-cse.github.io/cse450-course/module-05/\n",
        "\n"
      ],
      "metadata": {
        "id": "fgDPbgu2BxAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 1 - Test Accuracy: 0"
      ],
      "metadata": {
        "id": "O_fGtFYSNEzm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aRQkIOxDBtar",
        "outputId": "5997f61d-df5b-44ac-b2f7-d8071d5d8c11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 3.6778 - accuracy: 0.0572\n",
            "Epoch 1: val_loss improved from inf to 3.98036, saving model to model_weights.h5\n",
            "1003/1003 [==============================] - 79s 77ms/step - loss: 3.6778 - accuracy: 0.0572 - val_loss: 3.9804 - val_accuracy: 0.0233\n",
            "Epoch 2/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 3.3453 - accuracy: 0.1114\n",
            "Epoch 2: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 79s 79ms/step - loss: 3.3453 - accuracy: 0.1114 - val_loss: 4.8135 - val_accuracy: 0.0465\n",
            "Epoch 3/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 2.9614 - accuracy: 0.1968\n",
            "Epoch 3: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 76s 76ms/step - loss: 2.9614 - accuracy: 0.1968 - val_loss: 5.7595 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 2.5478 - accuracy: 0.2917\n",
            "Epoch 4: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 76s 76ms/step - loss: 2.5479 - accuracy: 0.2917 - val_loss: 6.8462 - val_accuracy: 0.0233\n",
            "Epoch 5/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 2.1594 - accuracy: 0.3901\n",
            "Epoch 5: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 76s 76ms/step - loss: 2.1594 - accuracy: 0.3901 - val_loss: 8.6074 - val_accuracy: 0.0233\n",
            "Epoch 6/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 1.8596 - accuracy: 0.4709\n",
            "Epoch 6: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 1.8596 - accuracy: 0.4709 - val_loss: 9.6772 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 1.6150 - accuracy: 0.5398\n",
            "Epoch 7: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 74ms/step - loss: 1.6150 - accuracy: 0.5398 - val_loss: 9.9251 - val_accuracy: 0.0233\n",
            "Epoch 8/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 1.4413 - accuracy: 0.5829\n",
            "Epoch 8: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 1.4417 - accuracy: 0.5829 - val_loss: 11.1362 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 1.2892 - accuracy: 0.6326\n",
            "Epoch 9: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 1.2893 - accuracy: 0.6326 - val_loss: 10.6222 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 1.1651 - accuracy: 0.6622\n",
            "Epoch 10: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 1.1651 - accuracy: 0.6622 - val_loss: 11.5577 - val_accuracy: 0.0233\n",
            "Epoch 11/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 1.0690 - accuracy: 0.6901\n",
            "Epoch 11: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 1.0690 - accuracy: 0.6901 - val_loss: 11.9392 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 0.9954 - accuracy: 0.7095\n",
            "Epoch 12: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 0.9954 - accuracy: 0.7095 - val_loss: 11.0816 - val_accuracy: 0.0233\n",
            "Epoch 13/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 0.9376 - accuracy: 0.7288\n",
            "Epoch 13: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 0.9377 - accuracy: 0.7286 - val_loss: 12.5323 - val_accuracy: 0.0465\n",
            "Epoch 14/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 0.8885 - accuracy: 0.7406\n",
            "Epoch 14: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 74s 74ms/step - loss: 0.8884 - accuracy: 0.7406 - val_loss: 12.9445 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 0.8435 - accuracy: 0.7566\n",
            "Epoch 15: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 74s 74ms/step - loss: 0.8435 - accuracy: 0.7566 - val_loss: 13.8580 - val_accuracy: 0.0233\n",
            "Epoch 16/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 0.8023 - accuracy: 0.7655\n",
            "Epoch 16: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 74s 74ms/step - loss: 0.8023 - accuracy: 0.7655 - val_loss: 12.7776 - val_accuracy: 0.0233\n",
            "Epoch 17/20\n",
            "1003/1003 [==============================] - ETA: 0s - loss: 0.7812 - accuracy: 0.7740\n",
            "Epoch 17: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 74ms/step - loss: 0.7812 - accuracy: 0.7740 - val_loss: 13.4298 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 0.7492 - accuracy: 0.7813\n",
            "Epoch 18: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 0.7491 - accuracy: 0.7813 - val_loss: 12.6107 - val_accuracy: 0.0233\n",
            "Epoch 19/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 0.7270 - accuracy: 0.7903\n",
            "Epoch 19: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 74s 74ms/step - loss: 0.7270 - accuracy: 0.7904 - val_loss: 13.6932 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "1002/1003 [============================>.] - ETA: 0s - loss: 0.6993 - accuracy: 0.7955\n",
            "Epoch 20: val_loss did not improve from 3.98036\n",
            "1003/1003 [==============================] - 75s 75ms/step - loss: 0.6998 - accuracy: 0.7953 - val_loss: 13.5169 - val_accuracy: 0.0000e+00\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 13.5169 - accuracy: 0.0000e+00\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Define the input shape and the number of classes\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 43\n",
        "\n",
        "# Define a function to load the dataset from the zip files\n",
        "def load_dataset():\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/test.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/test')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training1.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train1')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training2.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train2')\n",
        "\n",
        "    train_images, train_labels = [], []\n",
        "    test_images, test_labels = [], []\n",
        "\n",
        "    for root, _, files in os.walk('/content/train1'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/train2'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/test'):\n",
        "        for file in files:\n",
        "            label = int(file.split('.')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                test_images.append(image)\n",
        "                test_labels.append(label)\n",
        "\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = np.array(test_labels)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "# Define the CNN model architecture\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=False\n",
        ")\n",
        "\n",
        "# Generate augmented training data\n",
        "train_generator = datagen.flow(train_images, train_labels, batch_size=32)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_model()\n",
        "\n",
        "# Add model checkpoint callback to save the best model during training\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"model_weights.h5\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    mode=\"min\",\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.fit(train_generator, epochs=20, validation_data=(test_images, test_labels), callbacks=[checkpoint_callback])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "_, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 2 - Test Accuracy: 0.0233"
      ],
      "metadata": {
        "id": "MnWMqbAeFSur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Define the input shape and the number of classes\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 43\n",
        "\n",
        "# Define a function to load the dataset from the zip files\n",
        "def load_dataset():\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/test.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/test')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training1.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train1')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training2.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train2')\n",
        "\n",
        "    train_images, train_labels = [], []\n",
        "    test_images, test_labels = [], []\n",
        "\n",
        "    for root, _, files in os.walk('/content/train1'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/train2'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/test'):\n",
        "        for file in files:\n",
        "            label = int(file.split('.')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                test_images.append(image)\n",
        "                test_labels.append(label)\n",
        "\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = np.array(test_labels)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "# Define the CNN model architecture\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
        "          steps_per_epoch=len(train_images) // 32,\n",
        "          epochs=10,\n",
        "          validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "id": "OnJ3XJI1FQxB",
        "outputId": "e62f4de9-bee9-4ecc-b133-72ccb4150952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1002/1002 [==============================] - 84s 82ms/step - loss: 3.6453 - accuracy: 0.0605 - val_loss: 4.1210 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1002/1002 [==============================] - 82s 82ms/step - loss: 3.2824 - accuracy: 0.1199 - val_loss: 5.0222 - val_accuracy: 0.0233\n",
            "Epoch 3/10\n",
            "1002/1002 [==============================] - 87s 86ms/step - loss: 2.8694 - accuracy: 0.2144 - val_loss: 6.3963 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1002/1002 [==============================] - 81s 81ms/step - loss: 2.4526 - accuracy: 0.3169 - val_loss: 7.9345 - val_accuracy: 0.0465\n",
            "Epoch 5/10\n",
            "1002/1002 [==============================] - 83s 83ms/step - loss: 2.0576 - accuracy: 0.4202 - val_loss: 8.5850 - val_accuracy: 0.0233\n",
            "Epoch 6/10\n",
            "1002/1002 [==============================] - 83s 83ms/step - loss: 1.7251 - accuracy: 0.5084 - val_loss: 11.7172 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1002/1002 [==============================] - 82s 82ms/step - loss: 1.4699 - accuracy: 0.5764 - val_loss: 11.7717 - val_accuracy: 0.0233\n",
            "Epoch 8/10\n",
            "1002/1002 [==============================] - 82s 81ms/step - loss: 1.3073 - accuracy: 0.6230 - val_loss: 13.4370 - val_accuracy: 0.0233\n",
            "Epoch 9/10\n",
            "1002/1002 [==============================] - 82s 82ms/step - loss: 1.1424 - accuracy: 0.6704 - val_loss: 13.0127 - val_accuracy: 0.0233\n",
            "Epoch 10/10\n",
            "1002/1002 [==============================] - 83s 83ms/step - loss: 1.0404 - accuracy: 0.6964 - val_loss: 12.7169 - val_accuracy: 0.0233\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 12.7169 - accuracy: 0.0233\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12.71694278717041, 0.023255813866853714]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 3 - Increased Filters and added batch normalization layers"
      ],
      "metadata": {
        "id": "3B9u1xTWM9N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Define the input shape and the number of classes\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 43\n",
        "\n",
        "# Define a function to load the dataset from the zip files\n",
        "def load_dataset():\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/test.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/test')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training1.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train1')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training2.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train2')\n",
        "\n",
        "    train_images, train_labels = [], []\n",
        "    test_images, test_labels = [], []\n",
        "\n",
        "    for root, _, files in os.walk('/content/train1'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/train2'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/test'):\n",
        "        for file in files:\n",
        "            label = int(file.split('.')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                test_images.append(image)\n",
        "                test_labels.append(label)\n",
        "\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "# Create the model\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
        "          steps_per_epoch=len(train_images) // 32,\n",
        "          epochs=30,\n",
        "          validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "id": "vvsmmRvQNAD2",
        "outputId": "f156ebc6-e162-42e4-ebf2-21dd33c9ab9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1002/1002 [==============================] - 117s 115ms/step - loss: 3.8844 - accuracy: 0.0631 - val_loss: 4.0672 - val_accuracy: 0.0465\n",
            "Epoch 2/30\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 3.2809 - accuracy: 0.1355 - val_loss: 4.2798 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "1002/1002 [==============================] - 116s 116ms/step - loss: 2.9666 - accuracy: 0.2018 - val_loss: 4.4244 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 2.6810 - accuracy: 0.2675 - val_loss: 4.8918 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "1002/1002 [==============================] - 113s 113ms/step - loss: 2.4787 - accuracy: 0.3186 - val_loss: 5.2546 - val_accuracy: 0.0233\n",
            "Epoch 6/30\n",
            "1002/1002 [==============================] - 115s 114ms/step - loss: 2.3035 - accuracy: 0.3589 - val_loss: 5.2519 - val_accuracy: 0.0698\n",
            "Epoch 7/30\n",
            "1002/1002 [==============================] - 113s 113ms/step - loss: 2.1715 - accuracy: 0.3924 - val_loss: 5.6584 - val_accuracy: 0.0233\n",
            "Epoch 8/30\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 2.0538 - accuracy: 0.4240 - val_loss: 5.5607 - val_accuracy: 0.0233\n",
            "Epoch 9/30\n",
            "1002/1002 [==============================] - 115s 115ms/step - loss: 1.9557 - accuracy: 0.4473 - val_loss: 5.8534 - val_accuracy: 0.0233\n",
            "Epoch 10/30\n",
            "1002/1002 [==============================] - 117s 117ms/step - loss: 1.8807 - accuracy: 0.4653 - val_loss: 5.8461 - val_accuracy: 0.0233\n",
            "Epoch 11/30\n",
            "1002/1002 [==============================] - 115s 115ms/step - loss: 1.8169 - accuracy: 0.4833 - val_loss: 6.3620 - val_accuracy: 0.0233\n",
            "Epoch 12/30\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 1.7634 - accuracy: 0.4993 - val_loss: 6.2068 - val_accuracy: 0.0233\n",
            "Epoch 13/30\n",
            "1002/1002 [==============================] - 116s 116ms/step - loss: 1.7059 - accuracy: 0.5090 - val_loss: 6.2408 - val_accuracy: 0.0233\n",
            "Epoch 14/30\n",
            "1002/1002 [==============================] - 116s 115ms/step - loss: 1.6794 - accuracy: 0.5161 - val_loss: 6.1791 - val_accuracy: 0.0233\n",
            "Epoch 15/30\n",
            "1002/1002 [==============================] - 116s 116ms/step - loss: 1.6300 - accuracy: 0.5343 - val_loss: 6.3601 - val_accuracy: 0.0233\n",
            "Epoch 16/30\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 1.5937 - accuracy: 0.5406 - val_loss: 6.1697 - val_accuracy: 0.0233\n",
            "Epoch 17/30\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 1.5721 - accuracy: 0.5468 - val_loss: 6.3855 - val_accuracy: 0.0233\n",
            "Epoch 18/30\n",
            "1002/1002 [==============================] - 116s 115ms/step - loss: 1.5344 - accuracy: 0.5576 - val_loss: 6.4648 - val_accuracy: 0.0233\n",
            "Epoch 19/30\n",
            " 160/1002 [===>..........................] - ETA: 1:34 - loss: 1.5609 - accuracy: 0.5551"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-772bc18c2106>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n\u001b[0m\u001b[1;32m    100\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Eo2PXUukZymZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 4"
      ],
      "metadata": {
        "id": "4HrZk2pTZ0X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "\n",
        "# Define the input shape and the number of classes\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 43\n",
        "\n",
        "# Define a function to load the dataset from the zip files\n",
        "def load_dataset():\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/test.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/test')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training1.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train1')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training2.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train2')\n",
        "\n",
        "    train_images, train_labels = [], []\n",
        "    test_images, test_labels = [], []\n",
        "\n",
        "    for root, _, files in os.walk('/content/train1'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/train2'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/test'):\n",
        "        for file in files:\n",
        "            label = int(file.split('.')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                test_images.append(image)\n",
        "                test_labels.append(label)\n",
        "\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "# Create the model\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
        "          steps_per_epoch=len(train_images) // 32,\n",
        "          epochs=30,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "id": "OENHza_9Z2A2",
        "outputId": "9a2e138f-8ff8-468a-bf76-4a2e26fd0439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1002/1002 [==============================] - 189s 187ms/step - loss: 3.8671 - accuracy: 0.0683 - val_loss: 4.2070 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "1002/1002 [==============================] - 190s 189ms/step - loss: 3.2638 - accuracy: 0.1411 - val_loss: 4.4220 - val_accuracy: 0.0233 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "1002/1002 [==============================] - 188s 188ms/step - loss: 2.9518 - accuracy: 0.2089 - val_loss: 4.6435 - val_accuracy: 0.0233 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "1002/1002 [==============================] - ETA: 0s - loss: 2.7238 - accuracy: 0.2587\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "1002/1002 [==============================] - 186s 185ms/step - loss: 2.7238 - accuracy: 0.2587 - val_loss: 4.8454 - val_accuracy: 0.0233 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "1002/1002 [==============================] - 186s 185ms/step - loss: 2.4441 - accuracy: 0.3310 - val_loss: 4.7832 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "1002/1002 [==============================] - 186s 185ms/step - loss: 2.3490 - accuracy: 0.3552 - val_loss: 4.8154 - val_accuracy: 0.0465 - lr: 1.0000e-04\n",
            "Epoch 6: early stopping\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 4.8154 - accuracy: 0.0465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.815410614013672, 0.04651162773370743]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 5"
      ],
      "metadata": {
        "id": "UGsm8HelfnXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "\n",
        "# Define the input shape and the number of classes\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 43\n",
        "\n",
        "# Define a function to load the dataset from the zip files\n",
        "def load_dataset():\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/test.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/test')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training1.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train1')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training2.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train2')\n",
        "\n",
        "    train_images, train_labels = [], []\n",
        "    test_images, test_labels = [], []\n",
        "\n",
        "    for root, _, files in os.walk('/content/train1'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/train2'):\n",
        "        for file in files:\n",
        "            label = int(file.split('_')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "\n",
        "    for root, _, files in os.walk('/content/test'):\n",
        "        for file in files:\n",
        "            label = int(file.split('.')[0])\n",
        "            if label < num_classes:  # Check if the label is within the valid range\n",
        "                image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                image = keras.preprocessing.image.img_to_array(image)\n",
        "                test_images.append(image)\n",
        "                test_labels.append(label)\n",
        "\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "# Create the model\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1,\n",
        "                             horizontal_flip=True)\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
        "          steps_per_epoch=len(train_images) // 64,\n",
        "          epochs=15,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "id": "Mp6ogz9Hfk4C",
        "outputId": "75b78fac-9e3f-417e-c7ac-4b2205127a2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "501/501 [==============================] - 261s 517ms/step - loss: 4.7164 - accuracy: 0.0279 - val_loss: 3.9383 - val_accuracy: 0.0465 - lr: 1.0000e-04\n",
            "Epoch 2/15\n",
            "501/501 [==============================] - 254s 507ms/step - loss: 4.3463 - accuracy: 0.0366 - val_loss: 4.0081 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/15\n",
            "501/501 [==============================] - 254s 508ms/step - loss: 4.1513 - accuracy: 0.0436 - val_loss: 3.9616 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/15\n",
            "501/501 [==============================] - 254s 508ms/step - loss: 4.0203 - accuracy: 0.0489 - val_loss: 3.9178 - val_accuracy: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 5/15\n",
            "501/501 [==============================] - 254s 507ms/step - loss: 3.9190 - accuracy: 0.0576 - val_loss: 4.0329 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
            "Epoch 6/15\n",
            "501/501 [==============================] - 255s 509ms/step - loss: 3.8292 - accuracy: 0.0656 - val_loss: 3.9857 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
            "Epoch 7/15\n",
            "501/501 [==============================] - ETA: 0s - loss: 3.7493 - accuracy: 0.0710\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "501/501 [==============================] - 255s 508ms/step - loss: 3.7493 - accuracy: 0.0710 - val_loss: 4.0630 - val_accuracy: 0.0233 - lr: 1.0000e-04\n",
            "Epoch 8/15\n",
            "501/501 [==============================] - 254s 507ms/step - loss: 3.7059 - accuracy: 0.0775 - val_loss: 4.0111 - val_accuracy: 0.0233 - lr: 1.0000e-05\n",
            "Epoch 9/15\n",
            "501/501 [==============================] - 254s 507ms/step - loss: 3.6885 - accuracy: 0.0782 - val_loss: 4.0198 - val_accuracy: 0.0465 - lr: 1.0000e-05\n",
            "Epoch 9: early stopping\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 4.0198 - accuracy: 0.0465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.019769668579102, 0.04651162773370743]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 6 - not working"
      ],
      "metadata": {
        "id": "mc18vKdEttBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Define the input shape and the number of classes\n",
        "input_shape = (32, 32, 3)\n",
        "num_classes = 43\n",
        "\n",
        "# Define a function to load the dataset from the zip files\n",
        "def load_dataset():\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/test.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/test')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training1.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train1')\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Machine Learning/training2.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/train2')\n",
        "\n",
        "    train_images, train_labels = [], []\n",
        "    test_images, test_labels = [], []\n",
        "\n",
        "    def process_images(root, images, labels):\n",
        "        for file in os.listdir(root):\n",
        "            if file.endswith('.ppm'):\n",
        "                label = int(file.split('_')[0])\n",
        "                if label < num_classes:  # Check if the label is within the valid range\n",
        "                    image = keras.preprocessing.image.load_img(os.path.join(root, file), target_size=input_shape[:2])\n",
        "                    image = keras.preprocessing.image.img_to_array(image)\n",
        "                    images.append(image)\n",
        "                    labels.append(label)\n",
        "\n",
        "    process_images('/content/train1', train_images, train_labels)\n",
        "    process_images('/content/train2', train_images, train_labels)\n",
        "    process_images('/content/test', test_images, test_labels)\n",
        "\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, test_images, test_labels = load_dataset()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Create the model\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create data generators with augmentation\n",
        "datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1,\n",
        "                             horizontal_flip=True)\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "\n",
        "# Define callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(datagen.flow(train_images, train_labels, batch_size=64),\n",
        "          steps_per_epoch=len(train_images) // 64,\n",
        "          epochs=15,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "id": "3VwcC0u-tvS1",
        "outputId": "86658aa1-d4c4-4f8b-8e32-58429cae6c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c4ac2b683543>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1,\n\u001b[1;32m     88\u001b[0m                              horizontal_flip=True)\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Create the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m   2085\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2087\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2088\u001b[0m                 \u001b[0;34m\"Input to `.fit()` should have rank 4. Got array with shape: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input to `.fit()` should have rank 4. Got array with shape: (0,)"
          ]
        }
      ]
    }
  ]
}